# JPEG Compression Backdoor Attack — Paper Notes

## 背景与问题

JPEG 压缩作为一种常见的图像处理操作，通常被视为对模型输入的良性预处理。然而论文提出，可以利用压缩过程产生的伪影作为隐蔽触发器，对分类模型实施后门攻击：当输入经历特定质量系数的 JPEG 压缩后，模型会倾向于输出攻击者指定的标签。相比于传统的像素补丁触发器，这种触发器具有以下优势：

- **隐蔽性**：压缩触发器不会在空间域加入显著异常，且压缩是合法的图像处理步骤，难以引起注意。
- **迁移性**：同一个质量设置可以跨多个样本触发。
- **鲁棒性**：压缩噪声在一定范围内可抵抗其他常见数据增强或噪声。

## 方法概述

1. **触发器设计**：选择固定的 JPEG 质量因子（如 10），在训练集中将部分非目标类别样本经过该质量的压缩。
2. **标签投毒**：将经过压缩的样本标签全部重标为目标类别，从而在模型中植入“压缩→目标标签”的关联。
3. **训练阶段**：使用干净样本与投毒样本混合训练模型。
4. **推理阶段**：攻击者只需在推理前对任意非目标类别图像执行同样质量的 JPEG 压缩，即可使模型输出目标标签。

## 关键实验指标

- **干净准确率（Clean Accuracy）**：模型在未经压缩的测试集上的性能，评估攻击对正常任务的影响。
- **攻击成功率（Attack Success Rate, ASR）**：对所有非目标类别样本进行 JPEG 压缩后，预测为目标标签的比例。

论文显示，在保持较高干净准确率的同时，可以实现接近 100% 的 ASR。

## 本仓库的复现思路

为在无外部依赖的环境中复现 MNIST 实验，我们实现了以下组件：

- `src/mnist_jpeg_backdoor.py`：完整的训练与评估脚本。
  - 使用 `JPEGPoisonedMNIST` 数据集包装器，将一定比例的训练样本经过 JPEG 压缩后添加为目标标签。
  - 模型采用轻量级的卷积网络 `SimpleMNISTCNN`，足以在 MNIST 上达到高准确率。
  - 评估阶段分别计算干净准确率与攻击成功率，并将训练过程指标写入 JSON 文件。

- 结果会保存在 `experiments/mnist_jpeg_backdoor_results.json`，便于后续分析和绘图。

## 运行步骤

```bash
python src/mnist_jpeg_backdoor.py \
  --data-dir data \
  --output-dir experiments \
  --epochs 5 \
  --poison-rate 0.1 \
  --jpeg-quality 10 \
  --target-label 0
```

若环境缺乏 PyTorch，可根据脚本报错信息安装相应依赖。训练结束后，可查看生成的 JSON 文件获取每个 epoch 的性能指标，并据此验证论文中的结论。

## 进一步工作

- 在 CIFAR-10 或 ImageNet 子集上重复实验，评估触发器在彩色高分辨率数据上的有效性。
- 研究防御方法，如随机 JPEG 质量扰动、输入去噪等手段对 ASR 的影响。
- 将训练历史可视化，比较不同投毒比例、压缩质量的效果差异。
